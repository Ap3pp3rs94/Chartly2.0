version: "1.0"

connector_profile:
  id: "rss"
  protocol: "rss"
  kind: "domain"
  description: >
    RSS/Atom feed connector profile. Connector-hub fetches feed XML, applies politeness/compliance rules,
    deduplicates entries, stores raw feed and raw entry payloads as blobs, and emits normalize jobs.
  version: "1.0.0"
  status: "active"

source_config_schema:
  required_fields:
    - "url"
  optional_fields:
    - "timeout_seconds"
    - "rate_limit_rpm"
    - "headers"
    - "max_entries_per_fetch"
    - "dedupe"
    - "politeness"
  field_docs:
    url:
      type: "string"
      rules:
        - "Must be http(s) URL."
        - "No embedded credentials."
    headers:
      type: "object"
      rules:
        - "No secrets."
    max_entries_per_fetch:
      type: "integer"
      default: 100
      rules:
        - "Between 1 and 1000."

rss:
  url_policy:
    require_https: false
    forbid_embedded_credentials: true
  fetch_policy:
    timeout_seconds_default: 20
    follow_redirects: true
    headers_default:
      User-Agent: "Chartly/2.0"
      Accept: "application/rss+xml, application/atom+xml, application/xml, text/xml;q=0.9"
  conditional_get:
    planned: true
    etag_support: true
    last_modified_support: true
    notes:
      - "Store and reuse ETag/Last-Modified per source to reduce bandwidth."
      - "Conditional GET state stored in storage metadata (planned)."

politeness_and_compliance:
  tos_respect_required: true
  user_agent: "Chartly/2.0"
  crawl_delay_seconds_default: 10
  robots_respect:
    planned: true
    notes:
      - "RSS feeds typically publish content for consumption, but robots/ToS must still be respected."
  rate_limit_defaults:
    rate_limit_rpm: 30
    per_domain_concurrency: 2

deduplication:
  strategy: "entry_key_hash"
  entry_key_components_priority:
    - "guid"
    - "link"
    - "title+published_at"
  window_policy:
    enabled: false
    window_days: 0
  notes:
    - "Dedup at connector layer prevents repeated raw entry writes; idempotency in normalizer remains required."

payload_handling:
  store_raw_feed: true
  store_raw_entries: true
  max_entries_per_fetch_default: 100
  entry_extraction_policy:
    store_fields:
      - "guid"
      - "link"
      - "title"
      - "published_at"
      - "author"
      - "summary"
      - "content"
    notes:
      - "Do not attempt heavy HTML sanitization here; store raw entry content and let normalizer decide."
  raw_ref_requirements:
    - "Store feed XML as raw blob (sha256)."
    - "Store each entry (as JSON object) as raw blob or batch (implementation choice), each with sha256."
    - "Emit normalize jobs referencing raw_ref(s)."

observability:
  required_metrics:
    - "rss.fetch_total"
    - "rss.entries_seen_total"
    - "rss.entries_written_total"
    - "rss.errors_total"
  required_log_fields:
    - "ts"
    - "service=connector-hub"
    - "tenant_id"
    - "source_id"
    - "job_id"
    - "url"
    - "entries_seen"
    - "entries_written"
    - "raw_sha256"

llm_assist:
  enabled: true
  allowed_roles: ["schema_drift_explainer"]
  forbidden:
    - "increase_fetch_rate_without_human_approval"
    - "ignore_tos_or_robots"
  approval_gate: "human_required"
  audit_fields_required: ["llm_role", "model_id", "prompt_hash", "output_hash", "approver", "decision"]

# -----------------------------------------------------------------------------
# EXAMPLES (comments only)
#
# Example: Basic RSS feed
# source:
#   kind: domain
#   connector: rss
#   config:
#     url: "https://example.com/feed"
#     max_entries_per_fetch: 50
#     rate_limit_rpm: 15
# -----------------------------------------------------------------------------
